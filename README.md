# ğŸ¤Ÿ Indian Sign Language Recognition

Real-time Indian Sign Language (ISL) alphabet recognition using **MediaPipe hand landmarks** and a **deep neural network**. Recognises all **26 letters (Aâ€“Z)** from a live webcam feed with **98.27% accuracy**.

![ISL Recognition Demo](https://img.shields.io/badge/Accuracy-98.27%25-brightgreen) ![Python](https://img.shields.io/badge/Python-3.10%2B-blue) ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)

---

## âœ¨ Features

- ğŸ¥ **Real-time webcam** sign detection via browser
- ğŸ–ï¸ **MediaPipe hand tracking** with skeleton overlay
- ğŸ§  **195-feature rich extraction** (bend angles, fingertip distances, palm orientation, 2-hand support)
- âš¡ **EMA smoothing** for stable, flicker-free predictions
- ğŸ¨ **Premium dark UI** with live confidence bar
- ğŸ“Š **26 classes** (Aâ€“Z) with class-weighted training

---

## ğŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/YOUR_USERNAME/Indian-Sign-Language-Recognition.git
cd Indian-Sign-Language-Recognition
python -m venv .venv
.venv\Scripts\activate        # Windows
pip install -r requirements.txt
```

### 2. Run the App

```bash
python app.py
```

Open **http://127.0.0.1:5000** in your browser.

> The trained model (`isl_landmarks_model.keras`) is included â€” **no training needed** to run the app!

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                      # Flask server + webcam capture loop
â”œâ”€â”€ webcam_predict.py           # Model loading + inference
â”œâ”€â”€ feature_utils.py            # 195-float feature extraction (shared)
â”œâ”€â”€ train_landmarks.py          # Training script (only if retraining)
â”œâ”€â”€ collect_data.py             # Webcam data collection tool
â”œâ”€â”€ isl_landmarks_model.keras   # Trained model (98.27% accuracy)
â”œâ”€â”€ class_labels.txt            # Aâ€“Z class labels
â”œâ”€â”€ hand_landmarker.task        # MediaPipe hand detector model
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ templates/
    â””â”€â”€ index.html              # Web UI
```

---

## ğŸ“¦ Dataset

The training dataset (~0.57 GB, ~42,000 images) is too large for GitHub.

**ğŸ“¥ Download from Google Drive:**
ğŸ‘‰ [**ISL Dataset (Google Drive)**](https://drive.google.com/drive/folders/1GYyVNiVdhzvV48ZbQKHEaUNNt9iK0yT_?dmr=1)

After downloading, extract into the project root:
```
Indian-Sign-Language-Recognition/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ A/   (2426 images)
â”‚   â”œâ”€â”€ B/   (2528 images)
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ Z/   (1200 images)
```

> **Note:** You only need the dataset if you want to **retrain** the model. The pre-trained model is already included in the repo.

---

## ğŸ”„ Retrain (Optional)

If you want to retrain with new/additional data:

```bash
# Collect new data (e.g., 300 photos of letter R with 2 hands)
python collect_data.py R 300 2

# Retrain the model
python train_landmarks.py
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|---|---|
| Hand Detection | MediaPipe Hand Landmarker |
| ML Model | TensorFlow/Keras Dense NN |
| Feature Vector | 195 floats (angles + distances + orientation) |
| Backend | Flask |
| Frontend | HTML/CSS/JS |
| Webcam | OpenCV |

---

## ğŸ“Š Model Details

- **Architecture:** Dense 512â†’256â†’128â†’64â†’26 with BatchNorm + Dropout + L2
- **Features:** 195-float vector per sample (vs raw 63 XYZ coords)
- **Training:** Class-weighted, landmark augmentation (noise + rotation + scale)
- **Validation Accuracy:** 98.27%
- **Anti-overfitting:** EarlyStopping (patience=20), ReduceLROnPlateau

---

## ğŸ‘¥ Team

Built for Hackathon 2026 ğŸš€